{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Ingest Data into the SwimContainer\n",
    "\n",
    "This notebook demonstrates how to ingest extracted data into the SwimContainer. The container provides a unified `ingest` API for all data sources:\n",
    "\n",
    "- `container.ingest.ndvi()` - NDVI from Earth Engine exports\n",
    "- `container.ingest.etf()` - ETf from SSEBop or other models\n",
    "- `container.ingest.gridmet()` - Meteorology\n",
    "- `container.ingest.snodas()` - Snow water equivalent\n",
    "- `container.ingest.properties()` - Soils, LULC, irrigation\n",
    "\n",
    "## Two Data Sources\n",
    "\n",
    "1. **Extracted data**: If you ran notebook 02, data is in `data/landsat/extracts/`, `data/snodas/`, etc.\n",
    "2. **Pre-built data**: If you don't have Earth Engine access, use data from `data/prebuilt/`\n",
    "\n",
    "Set `USE_PREBUILT = True` or `False` below to choose your data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = os.path.abspath('../..')\n",
    "sys.path.append(root)\n",
    "\n",
    "from swimrs.container import open_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Choose whether to use pre-built data or extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to use pre-built data, False to use data from notebook 02\n",
    "USE_PREBUILT = False\n",
    "\n",
    "project_dir = Path.cwd()\n",
    "data_dir = project_dir / 'data'\n",
    "container_path = data_dir / '1_Boulder.swim'\n",
    "\n",
    "if USE_PREBUILT:\n",
    "    print(\"Using pre-built data from data/prebuilt/\")\n",
    "    ndvi_root = data_dir / 'prebuilt' / 'landsat_ndvi'\n",
    "    etf_root = data_dir / 'prebuilt' / 'landsat_etf'\n",
    "    met_dir = data_dir / 'prebuilt' / 'gridmet'\n",
    "    snodas_path = data_dir / 'prebuilt' / 'snodas' / 'snodas.json'\n",
    "    properties_dir = data_dir / 'prebuilt' / 'properties'\n",
    "else:\n",
    "    print(\"Using extracted data from notebook 02\")\n",
    "    ndvi_root = data_dir / 'landsat' / 'extracts' / 'ndvi'\n",
    "    etf_root = data_dir / 'landsat' / 'extracts' / 'etf'\n",
    "    met_dir = data_dir / 'met_timeseries' / 'gridmet'\n",
    "    snodas_path = data_dir / 'snodas' / 'snodas.json'\n",
    "    properties_dir = data_dir / 'properties'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open the Container\n",
    "\n",
    "Open the container we created in notebook 01 in read-write mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = open_container(str(container_path), mode='r+')\n",
    "\n",
    "print(f\"Opened container: {container.project_name}\")\n",
    "print(f\"Fields: {container.n_fields}\")\n",
    "print(f\"Date range: {container.start_date} to {container.end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Current Status\n",
    "\n",
    "Before ingestion, let's see what data the container currently holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.query.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ingest NDVI Data\n",
    "\n",
    "Ingest NDVI for both irrigated (`irr`) and non-irrigated (`inv_irr`) masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in ['irr', 'inv_irr']:\n",
    "    ndvi_dir = ndvi_root / mask\n",
    "    if ndvi_dir.exists():\n",
    "        print(f\"Ingesting NDVI ({mask})...\")\n",
    "        container.ingest.ndvi(\n",
    "            csv_dir=str(ndvi_dir),\n",
    "            instrument='landsat',\n",
    "            mask=mask,\n",
    "            overwrite=True\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: NDVI directory not found: {ndvi_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ingest ETf Data\n",
    "\n",
    "Ingest SSEBop ETf for both masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in ['irr', 'inv_irr']:\n",
    "    etf_dir = etf_root / mask\n",
    "    if etf_dir.exists():\n",
    "        print(f\"Ingesting ETf ({mask})...\")\n",
    "        container.ingest.etf(\n",
    "            csv_dir=str(etf_dir),\n",
    "            instrument='landsat',\n",
    "            model='ssebop',\n",
    "            mask=mask,\n",
    "            overwrite=True\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: ETf directory not found: {etf_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ingest Meteorology Data\n",
    "\n",
    "Ingest GridMET meteorology including bias-corrected reference ET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if met_dir.exists():\n",
    "    print(\"Ingesting GridMET meteorology...\")\n",
    "    container.ingest.gridmet(\n",
    "        source_dir=str(met_dir),\n",
    "        variables=['eto', 'etr', 'prcp', 'tmin', 'tmax', 'srad', 'u2', 'ea'],\n",
    "        include_corrected=True,\n",
    "        overwrite=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"Warning: GridMET directory not found: {met_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ingest Snow Data (SNODAS)\n",
    "\n",
    "Ingest SNODAS snow water equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if snodas_path.exists():\n",
    "    print(\"Ingesting SNODAS SWE...\")\n",
    "    container.ingest.snodas(\n",
    "        json_path=str(snodas_path),\n",
    "        overwrite=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"Warning: SNODAS file not found: {snodas_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ingest Properties\n",
    "\n",
    "Ingest static properties: soils, land cover, and irrigation fractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soils_csv = properties_dir / '1_Boulder_ssurgo.csv'\n",
    "lulc_csv = properties_dir / '1_Boulder_landcover.csv'\n",
    "irr_csv = properties_dir / '1_Boulder_irr.csv'\n",
    "\n",
    "# Check which files exist\n",
    "props_exist = {\n",
    "    'soils': soils_csv.exists(),\n",
    "    'lulc': lulc_csv.exists(),\n",
    "    'irrigation': irr_csv.exists()\n",
    "}\n",
    "\n",
    "if any(props_exist.values()):\n",
    "    print(\"Ingesting properties...\")\n",
    "    container.ingest.properties(\n",
    "        soils_csv=str(soils_csv) if props_exist['soils'] else None,\n",
    "        lulc_csv=str(lulc_csv) if props_exist['lulc'] else None,\n",
    "        irr_csv=str(irr_csv) if props_exist['irrigation'] else None,\n",
    "        overwrite=True\n",
    "    )\n",
    "    print(f\"  Soils: {'OK' if props_exist['soils'] else 'not found'}\")\n",
    "    print(f\"  Land cover: {'OK' if props_exist['lulc'] else 'not found'}\")\n",
    "    print(f\"  Irrigation: {'OK' if props_exist['irrigation'] else 'not found'}\")\n",
    "else:\n",
    "    print(f\"Warning: No property files found in {properties_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check Container Status After Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.query.status(detailed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Explore Ingested Data with xarray\n",
    "\n",
    "One of the powerful features of the SwimContainer is seamless xarray integration. Let's visualize some of the ingested data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NDVI as an xarray DataArray\n",
    "try:\n",
    "    ndvi = container.to_xarray('remote_sensing/ndvi/landsat/irr')\n",
    "    print(f\"NDVI shape: {ndvi.shape}\")\n",
    "    print(f\"Dimensions: {ndvi.dims}\")\n",
    "    print(f\"Sites: {list(ndvi.site.values[:5])}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load NDVI: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NDVI time series for a single field\n",
    "try:\n",
    "    sample_site = container.field_uids[0]\n",
    "    ndvi_site = ndvi.sel(site=sample_site)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    ndvi_site.plot(ax=ax, marker='.', linestyle='none', markersize=2)\n",
    "    ax.set_title(f'NDVI Time Series - Field {sample_site}')\n",
    "    ax.set_ylabel('NDVI')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot NDVI: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ETf vs ETo for a single year\n",
    "try:\n",
    "    etf = container.to_xarray('remote_sensing/etf/landsat/ssebop/irr')\n",
    "    eto = container.to_xarray('meteorology/gridmet/eto')\n",
    "    \n",
    "    # Select one site and one year\n",
    "    sample_site = container.field_uids[0]\n",
    "    etf_2020 = etf.sel(site=sample_site, time='2020')\n",
    "    eto_2020 = eto.sel(site=sample_site, time='2020')\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "    \n",
    "    axes[0].plot(eto_2020.time, eto_2020, 'b-', alpha=0.7, label='ETo')\n",
    "    axes[0].set_ylabel('ETo (mm/day)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(etf_2020.time, etf_2020, 'go', markersize=3, label='ETf')\n",
    "    axes[1].set_ylabel('ETf (fraction)')\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    fig.suptitle(f'Reference ET and ETf - Field {sample_site} (2020)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot ETf/ETo: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Provenance\n",
    "\n",
    "The container automatically tracks all operations for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Provenance Log:\")\n",
    "for event in container.provenance.events[-10:]:\n",
    "    print(f\"  {event.timestamp[:19]} - {event.operation}: {event.target or 'container'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save and Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.save()\n",
    "container.close()\n",
    "\n",
    "print(f\"Container saved to: {container_path}\")\n",
    "print(\"\\nNext: Run notebook 04 to compute dynamics and export model inputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
