{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Step 4: Compute Derived Products and Export Model Inputs\n\nWith data ingested into the container, we now compute derived products:\n\n1. **Merged NDVI** - Combine Landsat + Sentinel for better temporal coverage (if both available)\n2. **Dynamics** - Irrigation windows, groundwater subsidy, K parameters\n\nThen we export the `prepped_input.json` file that the SWIM model needs.\n\nThe container's `compute` and `export` APIs make this straightforward:\n- `container.compute.merged_ndvi()` - Merge sensors (already harmonized via SBAF)\n- `container.compute.dynamics()` - Compute irrigation/groundwater parameters\n- `container.export.prepped_input_json()` - Export model-ready JSON"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = os.path.abspath('../..')\n",
    "sys.path.append(root)\n",
    "\n",
    "from swimrs.container import open_container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open the Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened container: 1_Boulder\n",
      "Fields: 78\n"
     ]
    }
   ],
   "source": [
    "project_dir = Path.cwd()\n",
    "container_path = project_dir / 'data' / '1_Boulder.swim'\n",
    "\n",
    "container = open_container(str(container_path), mode='r+')\n",
    "\n",
    "print(f\"Opened container: {container.project_name}\")\n",
    "print(f\"Fields: {container.n_fields}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Current Status\n",
    "\n",
    "Let's verify the data was ingested correctly in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONTAINER STATUS\n",
      "============================================================\n",
      "  URI: file:///home/dgketchum/code/swim-rs/examples/1_Boulder/data/1_Boulder.swim\n",
      "  Storage: directory\n",
      "  Fields: 78\n",
      "  Date range: 2004-01-01 to 2022-12-31\n",
      "  Days: 6940\n",
      "\n",
      "DATA PATHS:\n",
      "----------------------------------------\n",
      "\n",
      "  geometry/\n",
      "    area_m2: shape=(78,), 100.0% valid\n",
      "    lat: shape=(78,), 100.0% valid\n",
      "    lon: shape=(78,), 100.0% valid\n",
      "    properties/COUNTYNAME: shape=(78,), 100.0% non-empty\n",
      "    properties/COUNTY_NO: shape=(78,), 100.0% valid\n",
      "    properties/ITYPE: shape=(78,), 100.0% non-empty\n",
      "    properties/MAPPEDBY: shape=(78,), 100.0% non-empty\n",
      "    properties/New_Acres: shape=(78,), 100.0% valid\n",
      "    properties/SOURCECODE: shape=(78,), 100.0% non-empty\n",
      "    properties/STATE: shape=(78,), 100.0% non-empty\n",
      "    properties/USAGE: shape=(78,), 100.0% valid\n",
      "    uid: shape=(78,), 100.0% non-empty\n",
      "    wkb: shape=(78,), 100.0% non-empty\n",
      "\n",
      "  meteorology/\n",
      "    gridmet/ea: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/eto: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/eto_corr: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/etr: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/etr_corr: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/prcp: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/srad: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/tmax: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/tmin: shape=(6940, 78), 100.0% valid\n",
      "    gridmet/u2: shape=(6940, 78), 100.0% valid\n",
      "\n",
      "  properties/\n",
      "    irrigation/irr: shape=(78,), 100.0% valid\n",
      "    irrigation/irr_yearly: shape=(78,), 100.0% non-empty\n",
      "    land_cover/modis_lc: shape=(78,), dtype=int16\n",
      "    soils/awc: shape=(78,), 100.0% valid\n",
      "    soils/clay: shape=(78,), 100.0% valid\n",
      "    soils/ksat: shape=(78,), 100.0% valid\n",
      "    soils/sand: shape=(78,), 100.0% valid\n",
      "\n",
      "  remote_sensing/\n",
      "    etf/landsat/ssebop/inv_irr: shape=(6940, 78), 12.8% valid\n",
      "    etf/landsat/ssebop/irr: shape=(6940, 78), 14.9% valid\n",
      "    ndvi/landsat/inv_irr: shape=(6940, 78), 5.5% valid\n",
      "    ndvi/landsat/irr: shape=(6940, 78), 6.5% valid\n",
      "\n",
      "  snow/\n",
      "    snodas/swe: shape=(6940, 78), 99.7% valid\n",
      "\n",
      "  time/\n",
      "    daily: shape=(6940,), dtype=datetime64[ns]\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(container.query.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2b. Visualize Landsat and Sentinel-2 NDVI\n\nBefore merging sensors, let's examine the individual NDVI time series from Landsat and Sentinel-2.\n\n**Spectral Harmonization**: All NDVI values were harmonized to the Landsat 8 OLI reference\nstandard during Earth Engine extraction using Spectral Bandpass Adjustment Factors (SBAF).\nThis ensures consistent values across the 40-year satellite record without post-hoc bias correction.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\n# Load NDVI from both sensors\nndvi_landsat = container.to_xarray('remote_sensing/ndvi/landsat/irr')\n\n# Check if Sentinel data exists\ntry:\n    ndvi_sentinel = container.to_xarray('remote_sensing/ndvi/sentinel/irr')\n    has_sentinel = True\n    print(\"Sentinel-2 NDVI loaded successfully\")\nexcept KeyError:\n    has_sentinel = False\n    print(\"Sentinel-2 NDVI not available - showing Landsat only\")\n\n# Select a sample field and year (2020, when both sensors overlap)\nsample_site = container.field_uids[0]\nyear = '2020'\n\nfig, ax = plt.subplots(figsize=(14, 5))\n\n# Plot Landsat NDVI\nlandsat_year = ndvi_landsat.sel(site=sample_site, time=year)\nax.plot(landsat_year.time, landsat_year, 'bo', markersize=6, alpha=0.7, label='Landsat')\n\n# Plot Sentinel NDVI if available\nif has_sentinel:\n    sentinel_year = ndvi_sentinel.sel(site=sample_site, time=year)\n    ax.plot(sentinel_year.time, sentinel_year, 'r^', markersize=5, alpha=0.7, label='Sentinel-2')\n\nax.set_ylabel('NDVI')\nax.set_xlabel('Date')\nax.set_title(f'Landsat vs Sentinel-2 NDVI - Field {sample_site} ({year})')\nax.legend()\nax.set_ylim(0, 1)\nplt.tight_layout()\nplt.show()\n\n# Count observations\nn_landsat = int(landsat_year.notnull().sum())\nprint(f\"\\nObservations in {year}:\")\nprint(f\"  Landsat: {n_landsat}\")\nif has_sentinel:\n    n_sentinel = int(sentinel_year.notnull().sum())\n    print(f\"  Sentinel-2: {n_sentinel}\")\n    print(f\"  Combined: {n_landsat + n_sentinel}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Merge NDVI from Multiple Sensors\n\nIf we have both Landsat and Sentinel NDVI, we can merge them into a single time series with\nbetter temporal coverage. Since sensors were harmonized via SBAF during extraction, this is a\nsimple chronological merge - no bias correction needed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Merging NDVI from Landsat and Sentinel...\")\ntry:\n    container.compute.merged_ndvi(\n        masks=('irr', 'inv_irr'),\n        instruments=('landsat', 'sentinel'),\n        preference_order=('landsat', 'sentinel'),  # Prefer Landsat when both have data on same date\n        overwrite=True\n    )\n    print(\"Merged NDVI computed successfully\")\nexcept Exception as e:\n    print(f\"Note: NDVI merge: {e}\")\n    print(\"Continuing with single-sensor NDVI...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Dynamics\n",
    "\n",
    "This is the heart of SWIM-RS preprocessing. The dynamics computation:\n",
    "\n",
    "- **Irrigation Windows**: Identifies periods when irrigation likely occurred based on NDVI patterns\n",
    "- **Groundwater Subsidy**: Detects fields receiving groundwater contributions to ET\n",
    "- **K Parameters**: Computes ke_max (evaporation coefficient) and kc_max (crop coefficient)\n",
    "\n",
    "The `use_mask=True` setting uses the annual irrigation fraction from IrrMapper/LANID to classify fields as irrigated vs non-irrigated. Otherwise (outside CONUS for now) we use a land cover map to determine if a field is a crop, and if so, apply irrigation if excess ET is detected or groundwater subsidy if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing dynamics...\n",
      "Dynamics computed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing dynamics...\")\n",
    "container.compute.dynamics(\n",
    "    etf_model='ssebop',\n",
    "    masks=('irr', 'inv_irr'),\n",
    "    irr_threshold=0.3,  # Fields with >30% irrigated area are considered irrigated\n",
    "    use_mask=True,      # Use irrigation mask from properties\n",
    "    use_lulc=False,     # Don't compute irrigation from water balance (CONUS mode)\n",
    "    lookback=5,         # Days to look back for irrigation window extension\n",
    "    overwrite=True\n",
    ")\n",
    "print(\"Dynamics computed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore Computed Dynamics\n",
    "\n",
    "Let's look at the irrigation windows for a sample field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get irrigation windows for a few fields\n",
    "sample_fields = container.field_uids[:3]\n",
    "try:\n",
    "    irr_windows = container.compute.irrigation_windows(fields=sample_fields)\n",
    "    \n",
    "    for fid in sample_fields:\n",
    "        if fid in irr_windows:\n",
    "            print(f\"\\nField {fid}:\")\n",
    "            for year in ['2018', '2019', '2020']:\n",
    "                if year in irr_windows[fid]:\n",
    "                    doys = irr_windows[fid][year].get('irr_doys', [])\n",
    "                    if doys:\n",
    "                        print(f\"  {year}: {len(doys)} irrigation days (DOY {min(doys)}-{max(doys)})\")\n",
    "                    else:\n",
    "                        print(f\"  {year}: No irrigation detected\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve irrigation windows: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize NDVI with Irrigation Periods\n",
    "\n",
    "Let's plot NDVI time series with irrigation periods marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ndvi = container.to_xarray('remote_sensing/ndvi/landsat/irr')\n",
    "    sample_site = container.field_uids[0]\n",
    "    \n",
    "    # Get 2020 data\n",
    "    ndvi_2020 = ndvi.sel(site=sample_site, time='2020')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    \n",
    "    # Plot NDVI\n",
    "    ax.plot(ndvi_2020.time, ndvi_2020, 'go', markersize=4, label='NDVI')\n",
    "    \n",
    "    # Mark irrigation season (approximate: DOY 150-270)\n",
    "    ax.axvspan('2020-05-30', '2020-09-27', alpha=0.2, color='blue', label='Typical irrigation season')\n",
    "    \n",
    "    ax.set_ylabel('NDVI')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_title(f'NDVI Time Series with Irrigation Season - Field {sample_site} (2020)')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not create visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check Container Status After Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container.query.status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Model Input JSON\n",
    "\n",
    "Finally, export the `prepped_input.json` file that the SWIM model needs. This contains:\n",
    "- Field properties (soils, area, irrigation fraction)\n",
    "- Irrigation data (per-year irrigation windows)\n",
    "- Time series data (meteorology, remote sensing)\n",
    "- Field ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "output_path = project_dir / 'data' / 'prepped_input.json'\n\nprint(\"Exporting model input JSON...\")\ncontainer.export.prepped_input_json(\n    output_path=str(output_path),\n    etf_model='ssebop',\n    masks=('irr', 'inv_irr'),\n    instrument='landsat',\n    use_merged_ndvi=True,\n    irr_threshold=0.3\n)\n\nprint(f\"\\nExported to: {output_path}\")\nprint(f\"File size: {output_path.stat().st_size / 1024 / 1024:.1f} MB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verify Export\n",
    "\n",
    "Let's peek at the exported JSON structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(output_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Top-level keys:\", list(data.keys()))\n",
    "print(f\"\\nNumber of fields in 'order': {len(data.get('order', []))}\")\n",
    "print(f\"Number of fields in 'props': {len(data.get('props', {}))}\")\n",
    "print(f\"Number of dates in 'time_series': {len(data.get('time_series', {}))}\")\n",
    "\n",
    "# Show sample field properties\n",
    "if data.get('props'):\n",
    "    sample_fid = list(data['props'].keys())[0]\n",
    "    print(f\"\\nSample field properties ({sample_fid}):\")\n",
    "    for k, v in data['props'][sample_fid].items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save and Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.save()\n",
    "container.close()\n",
    "\n",
    "print(f\"Container saved.\")\n",
    "print(f\"\\nReady to run the model!\")\n",
    "print(\"Next: Run notebook 05 to execute the SWIM model and visualize outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}