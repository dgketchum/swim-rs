{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# Calibration Tutorial - Fort Peck, MT - Unirrigated Flux Plot\n",
    "\n",
    "## Step 1: Uncalibrated Model Run\n",
    "\n",
    "This tutorial focuses on calibrating SWIM-RS for a single unirrigated plot: a 3-pixel buffer around FluxNet's US-FPe eddy covariance station from John Volk's Flux ET benchmark dataset. The flux station provides independent observations of both meteorology and ET flux, allowing us to validate our model.\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading pre-built model input data from a SwimContainer\n",
    "2. Running the uncalibrated SWIM model\n",
    "3. Comparing model output with flux tower observations\n",
    "\n",
    "**Reference:** This example is based on John Volk's flux footprint study:\n",
    "- Paper: https://www.sciencedirect.com/science/article/pii/S0168192323000011\n",
    "- Data: https://www.sciencedirect.com/science/article/pii/S2352340923003931\n",
    "\n",
    "---\n",
    "\n",
    "### Data Pipeline\n",
    "\n",
    "**Input Data:** The `data/2_Fort_Peck.swim/` container stores pre-computed input data, so you can get started right away. If you want to build or rebuild the data for this example, we have provided scripts for reproduction:\n",
    "\n",
    "1. **Extract data** from Earth Engine and GridMET:\n",
    "   ```bash\n",
    "   cd data/\n",
    "   python extract_data.py           # Extract US-FPe only (default)\n",
    "   python extract_data.py --help    # See all options\n",
    "   ```\n",
    "\n",
    "2. **Sync from bucket** after EE tasks complete:\n",
    "   ```bash\n",
    "   gsutil -m rsync -r gs://wudr/2_Fort_Peck/ ./data/\n",
    "   ```\n",
    "\n",
    "3. **Build model inputs** using the container:\n",
    "   ```bash\n",
    "   cd data/\n",
    "   python build_inputs.py           # Build container\n",
    "   python build_inputs.py --rebuild # Force rebuild from scratch\n",
    "   ```\n",
    "\n",
    "The container (`data/2_Fort_Peck.swim/`) stores all ingested data with provenance tracking.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:44.669765547Z",
     "start_time": "2026-01-28T05:34:44.150394202Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:15.270684Z",
     "iopub.status.busy": "2026-01-28T17:37:15.270171Z",
     "iopub.status.idle": "2026-01-28T17:37:17.043681Z",
     "shell.execute_reply": "2026-01-28T17:37:17.042697Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "root = os.path.abspath('../..')\n",
    "sys.path.append(root)\n",
    "\n",
    "from swimrs.swim.config import ProjectConfig\n",
    "from swimrs.container import SwimContainer\n",
    "from swimrs.process.input import build_swim_input\n",
    "from swimrs.process.loop_fast import run_daily_loop_fast\n",
    "\n",
    "from swimrs.viz.swim_timeseries import plot_swim_timeseries\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-setup-header",
   "metadata": {},
   "source": [
    "## 1. Project Setup\n",
    "\n",
    "Define paths and unzip pre-built data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-paths",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:44.731028106Z",
     "start_time": "2026-01-28T05:34:44.673883444Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:17.048345Z",
     "iopub.status.busy": "2026-01-28T17:37:17.048026Z",
     "iopub.status.idle": "2026-01-28T17:37:17.054797Z",
     "shell.execute_reply": "2026-01-28T17:37:17.053856Z"
    }
   },
   "outputs": [],
   "source": [
    "project_ws = os.path.abspath('.')\n",
    "data = os.path.join(project_ws, 'data')\n",
    "\n",
    "config_file = os.path.join(project_ws, '2_Fort_Peck.toml')\n",
    "container_path = os.path.join(data, '2_Fort_Peck.swim')\n",
    "\n",
    "# Unzip flux tower data if needed\n",
    "flux_zip = os.path.join(data, 'US-FPe_daily_data.zip')\n",
    "flux_csv = os.path.join(data, 'US-FPe_daily_data.csv')\n",
    "\n",
    "if os.path.exists(flux_zip) and not os.path.exists(flux_csv):\n",
    "    print(\"Extracting US-FPe_daily_data.zip...\")\n",
    "    with zipfile.ZipFile(flux_zip, 'r') as z:\n",
    "        z.extractall(data)\n",
    "\n",
    "print(f\"Project workspace: {project_ws}\")\n",
    "print(f\"Config file: {config_file}\")\n",
    "print(f\"Container: {container_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-config",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:44.792656568Z",
     "start_time": "2026-01-28T05:34:44.733816510Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:17.058320Z",
     "iopub.status.busy": "2026-01-28T17:37:17.058113Z",
     "iopub.status.idle": "2026-01-28T17:37:17.065941Z",
     "shell.execute_reply": "2026-01-28T17:37:17.065015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the project configuration\n",
    "config = ProjectConfig()\n",
    "config.read_config(config_file, project_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nu3i2ej8thj",
   "metadata": {},
   "source": [
    "### Optional: Query Data from Container\n",
    "\n",
    "The SwimContainer provides direct access to ingested data for exploration and analysis.\n",
    "This is useful for inspecting data without running the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p59ryslf9ig",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:46.783829473Z",
     "start_time": "2026-01-28T05:34:44.795056240Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:17.069801Z",
     "iopub.status.busy": "2026-01-28T17:37:17.069571Z",
     "iopub.status.idle": "2026-01-28T17:37:19.190951Z",
     "shell.execute_reply": "2026-01-28T17:37:19.189524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example: Query data directly from the SwimContainer\n",
    "from swimrs.container import SwimContainer\n",
    "\n",
    "container_path = os.path.join(data, '2_Fort_Peck.swim')\n",
    "\n",
    "if os.path.exists(container_path):\n",
    "    container = SwimContainer.open(container_path, mode='r')\n",
    "\n",
    "    # List available fields\n",
    "    print(f\"Fields in container: {container.field_uids}\")\n",
    "\n",
    "    # Get all time series for a single field using field_timeseries\n",
    "    ts_df = container.query.field_timeseries('US-FPe')\n",
    "    print(f\"\\nTime series shape: {ts_df.shape}\")\n",
    "    print(f\"Variables: {list(ts_df.columns)[:10]}...\")\n",
    "\n",
    "    # Query specific data using dataframe with zarr paths\n",
    "    # Path structure: remote_sensing/{type}/{instrument}/{model}/{mask}\n",
    "    ndvi_df = container.query.dataframe(\"remote_sensing/ndvi/landsat/inv_irr\", fields=['US-FPe'])\n",
    "    print(f\"\\nNDVI observations: {ndvi_df.notna().sum().values[0]}\")\n",
    "\n",
    "    etf_df = container.query.dataframe(\"remote_sensing/etf/landsat/ssebop/inv_irr\", fields=['US-FPe'])\n",
    "    print(f\"ETf observations: {etf_df.notna().sum().values[0]}\")\n",
    "\n",
    "    # Show container status\n",
    "    print(\"\\n\" + container.query.status())\n",
    "\n",
    "    container.close()\n",
    "else:\n",
    "    print(f\"Container not found at {container_path}\")\n",
    "    print(\"Run: cd data && python build_inputs.py --rebuild\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-site-header",
   "metadata": {},
   "source": [
    "## 2. About the Study Site\n",
    "\n",
    "The US-FPe flux site is located at Fort Peck, Montana. We use a simple 150-meter buffer around the flux tower instead of the sophisticated flux footprint polygons from the Volk et al. study.\n",
    "\n",
    "According to IrrMapper data, this location has never been irrigated, making it ideal for testing non-irrigated model parameterization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-show-site",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:49.611195039Z",
     "start_time": "2026-01-28T05:34:46.868195041Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:19.196068Z",
     "iopub.status.busy": "2026-01-28T17:37:19.195539Z",
     "iopub.status.idle": "2026-01-28T17:37:21.936458Z",
     "shell.execute_reply": "2026-01-28T17:37:21.935608Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import contextily as ctx\n",
    "\n",
    "gdf = gpd.read_file(config.fields_shapefile)\n",
    "selected_feature = 'US-FPe'\n",
    "\n",
    "print(f\"Site: {selected_feature}\")\n",
    "print(f\"Number of fields: {len(gdf)}\")\n",
    "\n",
    "# Plot the study area\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "gdf_plot = gdf.to_crs(epsg=3857)\n",
    "gdf_plot.plot(ax=ax, edgecolor='red', facecolor='yellow', alpha=0.5, linewidth=2)\n",
    "\n",
    "# Zoom out by expanding bounds (5km buffer around site)\n",
    "bounds = gdf_plot.total_bounds\n",
    "buffer = 1000  # buffer in meters\n",
    "ax.set_xlim(bounds[0] - buffer, bounds[2] + buffer)\n",
    "ax.set_ylim(bounds[1] - buffer, bounds[3] + buffer)\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.Esri.WorldImagery)\n",
    "\n",
    "ax.set_title(f'US-FPe Flux Site - Fort Peck, MT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-run-header",
   "metadata": {},
   "source": [
    "## 3. Run the Uncalibrated Model\n",
    "\n",
    "### Initial Parameter Values\n",
    "\n",
    "Before running the model, let's examine the default parameter values and their bounds. These parameters control the soil water balance and ET partitioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xq5p2q4xxum",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:49.718879129Z",
     "start_time": "2026-01-28T05:34:49.658691221Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:21.951642Z",
     "iopub.status.busy": "2026-01-28T17:37:21.951127Z",
     "iopub.status.idle": "2026-01-28T17:37:21.963381Z",
     "shell.execute_reply": "2026-01-28T17:37:21.962298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display default parameter values and bounds\n",
    "# These are the parameters that can be calibrated with PEST++\n",
    "\n",
    "def show_parameter_table():\n",
    "    \"\"\"Display parameter bounds and initial values.\"\"\"\n",
    "    # Static parameter definitions (from PestBuilder.initial_parameter_dict)\n",
    "    params = {\n",
    "        'aw': {'initial_value': None, 'lower_bound': 100.0, 'upper_bound': 400.0, 'std': 50.0},\n",
    "        'ks_alpha': {'initial_value': 0.5, 'lower_bound': 0.01, 'upper_bound': 1.0, 'std': 0.15},\n",
    "        'kr_alpha': {'initial_value': 0.5, 'lower_bound': 0.01, 'upper_bound': 1.0, 'std': 0.15},\n",
    "        'ndvi_k': {'initial_value': 7.0, 'lower_bound': 4.0, 'upper_bound': 10.0, 'std': 0.75},\n",
    "        'ndvi_0': {'initial_value': 0.4, 'lower_bound': 0.1, 'upper_bound': 0.7, 'std': 0.25},\n",
    "        'mad': {'initial_value': None, 'lower_bound': 0.01, 'upper_bound': 0.9, 'std': 0.15},\n",
    "        'swe_alpha': {'initial_value': 0.3, 'lower_bound': -0.5, 'upper_bound': 1.0, 'std': 0.2},\n",
    "        'swe_beta': {'initial_value': 1.5, 'lower_bound': 0.5, 'upper_bound': 2.5, 'std': 0.3},\n",
    "    }\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"INITIAL PARAMETER VALUES AND BOUNDS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Parameter':<12} {'Initial':>12} {'Lower':>10} {'Upper':>10} {'Std':>8}  Description\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    descriptions = {\n",
    "        'aw': 'Available water capacity (mm)',\n",
    "        'ks_alpha': 'Soil evap stress damping',\n",
    "        'kr_alpha': 'Root zone stress damping',\n",
    "        'ndvi_k': 'NDVI-Kcb slope',\n",
    "        'ndvi_0': 'NDVI-Kcb intercept',\n",
    "        'mad': 'Management allowable depletion',\n",
    "        'swe_alpha': 'Snow melt temp coefficient',\n",
    "        'swe_beta': 'Snow melt rate coefficient',\n",
    "    }\n",
    "\n",
    "    for name, p in params.items():\n",
    "        init = p['initial_value']\n",
    "        if init is None:\n",
    "            init_str = 'auto'\n",
    "        else:\n",
    "            init_str = f\"{init:.2f}\"\n",
    "        print(\n",
    "            f\"{name:<12} {init_str:>12} {p['lower_bound']:>10.2f} {p['upper_bound']:>10.2f} {p['std']:>8.2f}  {descriptions.get(name, '')}\")\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nNote: 'auto' values are computed from soil properties (awc) or defaults (mad=0.6)\")\n",
    "\n",
    "\n",
    "show_parameter_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:49.782747899Z",
     "start_time": "2026-01-28T05:34:49.721933669Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:21.967495Z",
     "iopub.status.busy": "2026-01-28T17:37:21.967216Z",
     "iopub.status.idle": "2026-01-28T17:37:21.981764Z",
     "shell.execute_reply": "2026-01-28T17:37:21.980795Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_fields(config, container, selected_feature, output_csv):\n",
    "    \"\"\"Run SWIM model using the process package and save output to CSV.\n",
    "    \n",
    "    Uses the modern process package workflow:\n",
    "    1. Build SwimInput from container\n",
    "    2. Run simulation with run_daily_loop_fast() for ~300x speedup\n",
    "    3. Convert DailyOutput to DataFrame with time series\n",
    "    4. Add ETf observations from container for comparison\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create temporary HDF5 for SwimInput\n",
    "    with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp:\n",
    "        temp_h5_path = tmp.name\n",
    "    \n",
    "    try:\n",
    "        # Build SwimInput from container\n",
    "        swim_input = build_swim_input(\n",
    "            container,\n",
    "            output_h5=temp_h5_path,\n",
    "            runoff_process=getattr(config, 'runoff_process', 'cn'),\n",
    "            etf_model=getattr(config, 'etf_target_model', 'ptjpl'),\n",
    "            met_source=getattr(config, 'met_source', 'gridmet'),\n",
    "            fields=[selected_feature],\n",
    "        )\n",
    "        \n",
    "        # Run simulation using the fast JIT-compiled loop\n",
    "        output, final_state = run_daily_loop_fast(swim_input)\n",
    "        \n",
    "        # Get time series data\n",
    "        n_days = swim_input.n_days\n",
    "        dates = pd.date_range(swim_input.start_date, periods=n_days, freq='D')\n",
    "        \n",
    "        # Get input time series for DataFrame\n",
    "        etr = swim_input.get_time_series('etr')\n",
    "        prcp = swim_input.get_time_series('prcp')\n",
    "        tmin = swim_input.get_time_series('tmin')\n",
    "        tmax = swim_input.get_time_series('tmax')\n",
    "        ndvi = swim_input.get_time_series('ndvi')\n",
    "        \n",
    "        # Build DataFrame (field index 0 since we're doing single field)\n",
    "        i = 0\n",
    "        df_data = {\n",
    "            # Model outputs\n",
    "            'et_act': output.eta[:, i],\n",
    "            'etref': etr[:, i],\n",
    "            'kc_act': output.etf[:, i],\n",
    "            'kc_bas': output.kcb[:, i],\n",
    "            'ks': output.ks[:, i],\n",
    "            'ke': output.ke[:, i],\n",
    "            'melt': output.melt[:, i],\n",
    "            'rain': output.rain[:, i],\n",
    "            'depl_root': output.depl_root[:, i],\n",
    "            'dperc': output.dperc[:, i],\n",
    "            'runoff': output.runoff[:, i],\n",
    "            'swe': output.swe[:, i],\n",
    "            'irrigation': output.irr_sim[:, i],\n",
    "            'gw_sim': output.gw_sim[:, i],\n",
    "            # Input time series\n",
    "            'ppt': prcp[:, i],\n",
    "            'tmin': tmin[:, i],\n",
    "            'tmax': tmax[:, i],\n",
    "            'tavg': (tmin[:, i] + tmax[:, i]) / 2.0,\n",
    "            'ndvi': ndvi[:, i],\n",
    "        }\n",
    "        \n",
    "        # Calculate derived columns\n",
    "        df_data['soil_water'] = swim_input.properties.awc[i] - output.depl_root[:, i]\n",
    "        \n",
    "        df = pd.DataFrame(df_data, index=dates)\n",
    "        \n",
    "        swim_input.close()\n",
    "        \n",
    "        # Load ETf observations from container for comparison\n",
    "        # These are the remote sensing observations (PT-JPL in this example)\n",
    "        etf_model = getattr(config, 'etf_target_model', 'ptjpl')\n",
    "        for mask in ['inv_irr', 'irr']:\n",
    "            etf_path = f\"remote_sensing/etf/landsat/{etf_model}/{mask}\"\n",
    "            try:\n",
    "                etf_df = container.query.dataframe(etf_path, fields=[selected_feature])\n",
    "                # Align with simulation dates\n",
    "                etf_series = etf_df[selected_feature].reindex(dates)\n",
    "                df[f'etf_{mask}'] = etf_series.values\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load ETf for {mask}: {e}\")\n",
    "                df[f'etf_{mask}'] = np.nan\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        if os.path.exists(temp_h5_path):\n",
    "            os.remove(temp_h5_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f'\\nExecution time: {end_time - start_time:.2f} seconds\\n')\n",
    "\n",
    "    df.to_csv(output_csv)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:51.330572804Z",
     "start_time": "2026-01-28T05:34:49.784547864Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:21.985478Z",
     "iopub.status.busy": "2026-01-28T17:37:21.985229Z",
     "iopub.status.idle": "2026-01-28T17:37:23.355262Z",
     "shell.execute_reply": "2026-01-28T17:37:23.354295Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_feature = 'US-FPe'\n",
    "out_csv = os.path.join(project_ws, f'combined_output_{selected_feature}_uncalibrated.csv')\n",
    "\n",
    "# Open container for model run\n",
    "container_path = os.path.join(data, '2_Fort_Peck.swim')\n",
    "container = SwimContainer.open(container_path, mode='r')\n",
    "\n",
    "try:\n",
    "    df = run_fields(config, container, selected_feature=selected_feature, output_csv=out_csv)\n",
    "finally:\n",
    "    container.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-inspect-output",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:51.462477775Z",
     "start_time": "2026-01-28T05:34:51.407211334Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:23.358942Z",
     "iopub.status.busy": "2026-01-28T17:37:23.358772Z",
     "iopub.status.idle": "2026-01-28T17:37:23.366024Z",
     "shell.execute_reply": "2026-01-28T17:37:23.365167Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Output shape: {df.shape}\")\n",
    "print(f\"\\nKey output columns:\")\n",
    "key_cols = ['et_act', 'etref', 'kc_act', 'kc_bas', 'ks', 'ke', 'melt', 'rain',\n",
    "            'depl_root', 'swe', 'ppt', 'irrigation', 'soil_water']\n",
    "for col in key_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  {col}: mean={df[col].mean():.3f}, max={df[col].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-viz-header",
   "metadata": {},
   "source": [
    "## 4. Visualize Model Output\n",
    "\n",
    "Let's examine a single year (2004) to see the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-viz-year",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:54.170006515Z",
     "start_time": "2026-01-28T05:34:51.464614048Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:23.370228Z",
     "iopub.status.busy": "2026-01-28T17:37:23.369782Z",
     "iopub.status.idle": "2026-01-28T17:37:26.290339Z",
     "shell.execute_reply": "2026-01-28T17:37:26.288602Z"
    }
   },
   "outputs": [],
   "source": [
    "ydf = df.loc['2004-01-01': '2004-12-31']\n",
    "print(f'Total irrigation: {ydf.irrigation.sum():.1f} mm')\n",
    "print(f'Total ET: {ydf.et_act.sum():.1f} mm')\n",
    "print(f'Total precipitation: {ydf.ppt.sum():.1f} mm')\n",
    "\n",
    "plot_swim_timeseries(ydf, ['et_act', 'etref', 'rain', 'melt', 'irrigation'],\n",
    "                     start='2004-01-01', end='2004-12-31', png_dir='et_uncalibrated.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-compare-header",
   "metadata": {},
   "source": [
    "## 5. Compare with Flux Tower Observations\n",
    "\n",
    "We compare three estimates of actual ET (mm/day):\n",
    "\n",
    "1. **SWIM ET**: Model-estimated actual evapotranspiration (daily)\n",
    "2. **PT-JPL ET**: Remote sensing retrievals from OpenET PT-JPL algorithm (ETf × ETo)\n",
    "3. **Flux ET**: Independent observations from the eddy covariance tower (Volk et al.)\n",
    "\n",
    "We show two comparisons:\n",
    "- **Full time series**: SWIM (daily) vs PT-JPL (interpolated between Landsat dates) on all flux tower days\n",
    "- **Capture dates only**: Both methods compared only on Landsat overpass dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compare-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:54.310541444Z",
     "start_time": "2026-01-28T05:34:54.243365048Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:26.295995Z",
     "iopub.status.busy": "2026-01-28T17:37:26.295486Z",
     "iopub.status.idle": "2026-01-28T17:37:26.317745Z",
     "shell.execute_reply": "2026-01-28T17:37:26.316673Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_et_estimates(combined_output_path, flux_data_path, irr=False):\n",
    "    \"\"\"Compare model ET and PT-JPL ET against flux tower observations.\n",
    "    \n",
    "    Returns two comparison DataFrames:\n",
    "    1. Capture dates only: Both methods on Landsat overpass dates only\n",
    "    2. Full time series: SWIM daily, PT-JPL interpolated, on all flux tower days\n",
    "    \n",
    "    Reports R², Pearson r, bias, and RMSE for each comparison.\n",
    "    \"\"\"\n",
    "    flux_data = pd.read_csv(flux_data_path, index_col='date', parse_dates=True)\n",
    "    flux_et = flux_data['ET']  # Actual ET from flux tower (mm/day)\n",
    "\n",
    "    output = pd.read_csv(combined_output_path, index_col=0)\n",
    "    output.index = pd.to_datetime(output.index)\n",
    "\n",
    "    etf_col = 'etf_irr' if irr else 'etf_inv_irr'\n",
    "\n",
    "    # Calculate actual ET from PT-JPL: ETf × ETo (sparse, only on Landsat dates)\n",
    "    ptjpl_et_sparse = output[etf_col] * output['etref']\n",
    "\n",
    "    # Linear interpolation of PT-JPL to get daily values\n",
    "    ptjpl_et_interp = ptjpl_et_sparse.interpolate(method='linear')\n",
    "\n",
    "    # Count original PT-JPL observations\n",
    "    n_ptjpl_obs = ptjpl_et_sparse.notna().sum()\n",
    "\n",
    "    # CAPTURE DATES ONLY comparison (PT-JPL sparse)\n",
    "    capture_df = pd.DataFrame({\n",
    "        'swim_et': output['et_act'],\n",
    "        'ptjpl_et': ptjpl_et_sparse,\n",
    "        'flux_et': flux_et\n",
    "    }).dropna()\n",
    "\n",
    "    # FULL TIME SERIES comparison (PT-JPL interpolated)\n",
    "    full_df = pd.DataFrame({\n",
    "        'swim_et': output['et_act'],\n",
    "        'ptjpl_et': ptjpl_et_interp,\n",
    "        'flux_et': flux_et\n",
    "    }).dropna()\n",
    "\n",
    "    def calc_metrics(df, col1, col2):\n",
    "        r, _ = stats.pearsonr(df[col1], df[col2])\n",
    "        r2 = r2_score(df[col1], df[col2])\n",
    "        rmse = np.sqrt(mean_squared_error(df[col1], df[col2]))\n",
    "        bias = (df[col2] - df[col1]).mean()\n",
    "        return r2, r, rmse, bias\n",
    "\n",
    "    # Capture dates metrics\n",
    "    r2_swim_cap, r_swim_cap, rmse_swim_cap, bias_swim_cap = calc_metrics(capture_df, 'flux_et', 'swim_et')\n",
    "    r2_ptjpl_cap, r_ptjpl_cap, rmse_ptjpl_cap, bias_ptjpl_cap = calc_metrics(capture_df, 'flux_et', 'ptjpl_et')\n",
    "\n",
    "    # Full time series metrics\n",
    "    r2_swim_full, r_swim_full, rmse_swim_full, bias_swim_full = calc_metrics(full_df, 'flux_et', 'swim_et')\n",
    "    r2_ptjpl_full, r_ptjpl_full, rmse_ptjpl_full, bias_ptjpl_full = calc_metrics(full_df, 'flux_et', 'ptjpl_et')\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"CAPTURE DATES ONLY ({len(capture_df)} Landsat overpass dates)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Metric':<12} {'SWIM ET':>12} {'PT-JPL ET':>12}\")\n",
    "    print(\"-\" * 38)\n",
    "    print(f\"{'R²':<12} {r2_swim_cap:>12.3f} {r2_ptjpl_cap:>12.3f}\")\n",
    "    print(f\"{'Pearson r':<12} {r_swim_cap:>12.3f} {r_ptjpl_cap:>12.3f}\")\n",
    "    print(f\"{'Bias (mm)':<12} {bias_swim_cap:>12.3f} {bias_ptjpl_cap:>12.3f}\")\n",
    "    print(f\"{'RMSE (mm)':<12} {rmse_swim_cap:>12.3f} {rmse_ptjpl_cap:>12.3f}\")\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"FULL TIME SERIES ({len(full_df)} days, PT-JPL interpolated from {n_ptjpl_obs} obs)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Metric':<12} {'SWIM ET':>12} {'PT-JPL ET':>12}\")\n",
    "    print(\"-\" * 38)\n",
    "    print(f\"{'R²':<12} {r2_swim_full:>12.3f} {r2_ptjpl_full:>12.3f}\")\n",
    "    print(f\"{'Pearson r':<12} {r_swim_full:>12.3f} {r_ptjpl_full:>12.3f}\")\n",
    "    print(f\"{'Bias (mm)':<12} {bias_swim_full:>12.3f} {bias_ptjpl_full:>12.3f}\")\n",
    "    print(f\"{'RMSE (mm)':<12} {rmse_swim_full:>12.3f} {rmse_ptjpl_full:>12.3f}\")\n",
    "\n",
    "    return full_df, capture_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compare-run",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:54.453340404Z",
     "start_time": "2026-01-28T05:34:54.312603957Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:26.321807Z",
     "iopub.status.busy": "2026-01-28T17:37:26.321471Z",
     "iopub.status.idle": "2026-01-28T17:37:26.421835Z",
     "shell.execute_reply": "2026-01-28T17:37:26.420910Z"
    }
   },
   "outputs": [],
   "source": [
    "flux_data = os.path.join(data, 'US-FPe_daily_data.csv')\n",
    "full_df, capture_df = compare_et_estimates(out_csv, flux_data, irr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusion",
   "metadata": {},
   "source": [
    "## Summary ##\n",
    "\n",
    "The uncalibrated SWIM model shows moderate correlation with flux tower ET observations and relatively low bias. PT-JPL shows weaker correlation and tends to overestimate ET.\n",
    "\n",
    "**Next step:** In notebook `02_calibration.ipynb`, we'll use PEST++ to calibrate the model parameters and improve performance.\n",
    "\n",
    "**Note:** We're not using the flux data for calibration - it's only for validation. For calibration, we rely solely on widely-available remote sensing data (PT-JPL ETf and SNODAS SWE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scatter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:55.586839042Z",
     "start_time": "2026-01-28T05:34:54.455519406Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:26.425372Z",
     "iopub.status.busy": "2026-01-28T17:37:26.425206Z",
     "iopub.status.idle": "2026-01-28T17:37:27.391412Z",
     "shell.execute_reply": "2026-01-28T17:37:27.390686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create scatter plots for both comparisons\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "\n",
    "# Helper function to calculate metrics\n",
    "def calc_metrics(df, col1, col2):\n",
    "    r, _ = stats.pearsonr(df[col1], df[col2])\n",
    "    r2 = r2_score(df[col1], df[col2])\n",
    "    rmse = np.sqrt(mean_squared_error(df[col1], df[col2]))\n",
    "    return r2, r, rmse\n",
    "\n",
    "\n",
    "# Determine axis limits\n",
    "max_et = max(full_df['flux_et'].max(), full_df['swim_et'].max(),\n",
    "             full_df['ptjpl_et'].max()) * 1.1\n",
    "\n",
    "# TOP ROW: Capture dates only\n",
    "r2_swim_cap, r_swim_cap, rmse_swim_cap = calc_metrics(capture_df, 'flux_et', 'swim_et')\n",
    "r2_ptjpl_cap, r_ptjpl_cap, rmse_ptjpl_cap = calc_metrics(capture_df, 'flux_et', 'ptjpl_et')\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(capture_df['flux_et'], capture_df['swim_et'], alpha=0.5, s=15)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('SWIM ET (mm/day)')\n",
    "ax.set_title(f'SWIM vs Flux - Capture Dates (n={len(capture_df)})\\n'\n",
    "             f'R² = {r2_swim_cap:.3f}, r = {r_swim_cap:.3f}, RMSE = {rmse_swim_cap:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(capture_df['flux_et'], capture_df['ptjpl_et'], alpha=0.5, s=15)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('PT-JPL ET (mm/day)')\n",
    "ax.set_title(f'PT-JPL vs Flux - Capture Dates (n={len(capture_df)})\\n'\n",
    "             f'R² = {r2_ptjpl_cap:.3f}, r = {r_ptjpl_cap:.3f}, RMSE = {rmse_ptjpl_cap:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "# BOTTOM ROW: Full time series comparison\n",
    "r2_swim, r_swim, rmse_swim = calc_metrics(full_df, 'flux_et', 'swim_et')\n",
    "r2_ptjpl, r_ptjpl, rmse_ptjpl = calc_metrics(full_df, 'flux_et', 'ptjpl_et')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(full_df['flux_et'], full_df['swim_et'], alpha=0.3, s=10)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('SWIM ET (mm/day)')\n",
    "ax.set_title(f'SWIM vs Flux - Full Series (n={len(full_df)})\\n'\n",
    "             f'R² = {r2_swim:.3f}, r = {r_swim:.3f}, RMSE = {rmse_swim:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(full_df['flux_et'], full_df['ptjpl_et'], alpha=0.3, s=10)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('PT-JPL ET (mm/day)')\n",
    "ax.set_title(f'PT-JPL vs Flux - Full Series, interpolated (n={len(full_df)})\\n'\n",
    "             f'R² = {r2_ptjpl:.3f}, r = {r_ptjpl:.3f}, RMSE = {rmse_ptjpl:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_scatter_uncalibrated.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5w6yyvlrz6g",
   "metadata": {},
   "source": [
    "## 6. Mass Balance Check\n",
    "\n",
    "Verify water conservation across the full simulation period. The water balance equation:\n",
    "\n",
    "**Starting Water + Inputs - Outputs = Ending Water**\n",
    "\n",
    "Where:\n",
    "- **Starting Water** = Initial Soil Water + Initial SWE\n",
    "- **Inputs** = Precipitation + Irrigation  \n",
    "- **Outputs** = ET + Deep Percolation + Runoff\n",
    "- **Ending Water** = Final Soil Water + Final SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lo2co4k8je",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:55.732509133Z",
     "start_time": "2026-01-28T05:34:55.668736082Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T17:37:27.397769Z",
     "iopub.status.busy": "2026-01-28T17:37:27.397531Z",
     "iopub.status.idle": "2026-01-28T17:37:27.410423Z",
     "shell.execute_reply": "2026-01-28T17:37:27.409534Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mass_balance(df):\n",
    "    \"\"\"Compute full-run mass balance and display as a table.\n",
    "    \n",
    "    Water Balance: Starting Water + Inputs - Outputs = Ending Water\n",
    "    \n",
    "    Components:\n",
    "    - Starting Water: Initial soil water + Initial SWE\n",
    "    - Inputs: Total precipitation + Total irrigation\n",
    "    - Outputs: Total ET + Total deep percolation + Total runoff\n",
    "    - Ending Water: Final soil water + Final SWE\n",
    "    \"\"\"\n",
    "    # Starting conditions (first day values)\n",
    "    start_soil_water = df['soil_water'].iloc[0]\n",
    "    start_swe = df['swe'].iloc[0]\n",
    "    start_water = start_soil_water + start_swe\n",
    "    \n",
    "    # Ending conditions (last day values)\n",
    "    end_soil_water = df['soil_water'].iloc[-1]\n",
    "    end_swe = df['swe'].iloc[-1]\n",
    "    end_water = end_soil_water + end_swe\n",
    "    \n",
    "    # Inputs (sums over full period)\n",
    "    total_precip = df['ppt'].sum()\n",
    "    total_irrigation = df['irrigation'].sum()\n",
    "    total_inputs = total_precip + total_irrigation\n",
    "    \n",
    "    # Outputs (sums over full period)\n",
    "    total_et = df['et_act'].sum()\n",
    "    total_dperc = df['dperc'].sum()\n",
    "    total_runoff = df['runoff'].sum()\n",
    "    total_outputs = total_et + total_dperc + total_runoff\n",
    "    \n",
    "    # Mass balance check\n",
    "    # Expected: Start + Inputs - Outputs = End\n",
    "    # Residual: (Start + Inputs - Outputs) - End = 0 if balanced\n",
    "    expected_end = start_water + total_inputs - total_outputs\n",
    "    residual = expected_end - end_water\n",
    "    pct_error = (residual / total_inputs) * 100 if total_inputs > 0 else 0\n",
    "    \n",
    "    # Create summary table\n",
    "    print(\"=\" * 70)\n",
    "    print(\"MASS BALANCE SUMMARY\")\n",
    "    print(f\"Period: {df.index[0].strftime('%Y-%m-%d')} to {df.index[-1].strftime('%Y-%m-%d')} ({len(df)} days)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n--- STARTING WATER ---\")\n",
    "    print(f\"  Initial Soil Water:     {start_soil_water:>10.2f} mm\")\n",
    "    print(f\"  Initial SWE:            {start_swe:>10.2f} mm\")\n",
    "    print(f\"  TOTAL STARTING:         {start_water:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- INPUTS (+) ---\")\n",
    "    print(f\"  Precipitation:          {total_precip:>10.2f} mm\")\n",
    "    print(f\"  Irrigation:             {total_irrigation:>10.2f} mm\")\n",
    "    print(f\"  TOTAL INPUTS:           {total_inputs:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- OUTPUTS (-) ---\")\n",
    "    print(f\"  Evapotranspiration:     {total_et:>10.2f} mm\")\n",
    "    print(f\"  Deep Percolation:       {total_dperc:>10.2f} mm\")\n",
    "    print(f\"  Runoff:                 {total_runoff:>10.2f} mm\")\n",
    "    print(f\"  TOTAL OUTPUTS:          {total_outputs:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- ENDING WATER ---\")\n",
    "    print(f\"  Final Soil Water:       {end_soil_water:>10.2f} mm\")\n",
    "    print(f\"  Final SWE:              {end_swe:>10.2f} mm\")\n",
    "    print(f\"  TOTAL ENDING:           {end_water:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- BALANCE CHECK ---\")\n",
    "    print(f\"  Expected End (Start + In - Out):  {expected_end:>10.2f} mm\")\n",
    "    print(f\"  Actual End:                       {end_water:>10.2f} mm\")\n",
    "    print(f\"  Residual (Error):                 {residual:>10.2f} mm\")\n",
    "    print(f\"  Error as % of Inputs:             {pct_error:>10.4f} %\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if abs(pct_error) < 0.01:\n",
    "        print(\"MASS BALANCE: CLOSED (error < 0.01%)\")\n",
    "    elif abs(pct_error) < 1.0:\n",
    "        print(\"MASS BALANCE: ACCEPTABLE (error < 1%)\")\n",
    "    else:\n",
    "        print(f\"MASS BALANCE: WARNING - {abs(pct_error):.2f}% error\")\n",
    "    \n",
    "    return {\n",
    "        'start_soil_water': start_soil_water,\n",
    "        'start_swe': start_swe,\n",
    "        'end_soil_water': end_soil_water,\n",
    "        'end_swe': end_swe,\n",
    "        'precip': total_precip,\n",
    "        'irrigation': total_irrigation,\n",
    "        'et': total_et,\n",
    "        'dperc': total_dperc,\n",
    "        'runoff': total_runoff,\n",
    "        'residual': residual,\n",
    "        'pct_error': pct_error\n",
    "    }\n",
    "\n",
    "# Run mass balance check\n",
    "balance = compute_mass_balance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94caa6ab223a349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T05:34:55.783434454Z",
     "start_time": "2026-01-28T05:34:55.734254343Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
