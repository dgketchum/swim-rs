{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# Calibration Tutorial - Crane, OR - Irrigated Flux Plot\n",
    "\n",
    "## Step 1: Uncalibrated Model Run\n",
    "\n",
    "This tutorial focuses on calibrating SWIM-RS for a single irrigated alfalfa plot at the S2 flux station in Crane, Oregon. Unlike the unirrigated Fort Peck example, this site is actively irrigated.\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading pre-built model input data from a SwimContainer\n",
    "2. Running the uncalibrated SWIM model\n",
    "3. Comparing model output with the open source members of the OpenET ensemble (PT-JPL, SIMS, SSEBop, geeSEBAL)\n",
    "4. Validation against flux tower observations using multiple metrics (R², r, RMSE, bias)\n",
    "\n",
    "### Data Pipeline\n",
    "\n",
    "**Input Data:** The `data/3_Crane.swim/` container stores pre-computed input data.\n",
    "\n",
    "The full data workflow uses two scripts and can be re-run if needed:\n",
    "\n",
    "1. **`extract_data.py`** - Extracts raw data from Earth Engine and GridMET to CSV/parquet files\n",
    "2. **`build_inputs.py`** - Processes extracted data through SwimContainer\n",
    "\n",
    "To reproduce the input data from scratch:\n",
    "\n",
    "```bash\n",
    "cd data\n",
    "python extract_data.py    # Extract from EE/GridMET (requires authentication)\n",
    "python build_inputs.py    # Build container\n",
    "```\n",
    "\n",
    "See `data/extract_data.py` for extraction options and `data/build_inputs.py` for container workflow details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:04.247957644Z",
     "start_time": "2026-01-28T06:35:04.178379102Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:44.328632Z",
     "iopub.status.busy": "2026-01-28T18:00:44.327810Z",
     "iopub.status.idle": "2026-01-28T18:00:46.255374Z",
     "shell.execute_reply": "2026-01-28T18:00:46.254647Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "root = os.path.abspath('../..')\n",
    "sys.path.append(root)\n",
    "\n",
    "from swimrs.swim.config import ProjectConfig\n",
    "from swimrs.container import SwimContainer\n",
    "from swimrs.process.input import build_swim_input\n",
    "from swimrs.process.loop_fast import run_daily_loop_fast\n",
    "\n",
    "from swimrs.viz.swim_timeseries import plot_swim_timeseries\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-setup-header",
   "metadata": {},
   "source": [
    "## 1. Project Setup\n",
    "\n",
    "Define paths and unzip pre-built data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-paths",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:04.323744485Z",
     "start_time": "2026-01-28T06:35:04.249099206Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:46.260068Z",
     "iopub.status.busy": "2026-01-28T18:00:46.259732Z",
     "iopub.status.idle": "2026-01-28T18:00:46.265348Z",
     "shell.execute_reply": "2026-01-28T18:00:46.264745Z"
    }
   },
   "outputs": [],
   "source": [
    "project_ws = os.path.abspath('.')\n",
    "data = os.path.join(project_ws, 'data')\n",
    "\n",
    "config_file = os.path.join(project_ws, '3_Crane.toml')\n",
    "container_path = os.path.join(data, '3_Crane.swim')\n",
    "\n",
    "# Unzip flux tower data if needed\n",
    "flux_zip = os.path.join(data, 'S2_daily_data.zip')\n",
    "flux_csv = os.path.join(data, 'S2_daily_data.csv')\n",
    "\n",
    "if os.path.exists(flux_zip) and not os.path.exists(flux_csv):\n",
    "    print(\"Extracting S2_daily_data.zip...\")\n",
    "    with zipfile.ZipFile(flux_zip, 'r') as z:\n",
    "        z.extractall(data)\n",
    "\n",
    "print(f\"Project workspace: {project_ws}\")\n",
    "print(f\"Config file: {config_file}\")\n",
    "print(f\"Container: {container_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-config",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:04.397638431Z",
     "start_time": "2026-01-28T06:35:04.327726207Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:46.268939Z",
     "iopub.status.busy": "2026-01-28T18:00:46.268734Z",
     "iopub.status.idle": "2026-01-28T18:00:46.276272Z",
     "shell.execute_reply": "2026-01-28T18:00:46.275638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the project configuration\n",
    "config = ProjectConfig()\n",
    "config.read_config(config_file, project_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p1mbfjk45fs",
   "metadata": {},
   "source": [
    "### Initial Parameter Values\n",
    "\n",
    "The model will run with the following default parameter values and bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bprovbbl88t",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:04.519564597Z",
     "start_time": "2026-01-28T06:35:04.398916984Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:46.280074Z",
     "iopub.status.busy": "2026-01-28T18:00:46.279848Z",
     "iopub.status.idle": "2026-01-28T18:00:46.676823Z",
     "shell.execute_reply": "2026-01-28T18:00:46.675265Z"
    }
   },
   "outputs": [],
   "source": [
    "from swimrs.calibrate.pest_builder import PestBuilder\n",
    "\n",
    "def show_parameter_table(config, container_path):\n",
    "    \"\"\"Display parameter bounds and initial values from PestBuilder.\"\"\"\n",
    "    container = SwimContainer.open(container_path, mode='r')\n",
    "    try:\n",
    "        builder = PestBuilder(config, container=container)\n",
    "        params = builder.initial_parameter_dict()\n",
    "    finally:\n",
    "        container.close()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"INITIAL PARAMETER VALUES AND BOUNDS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Parameter':<12} {'Initial':>12} {'Lower':>10} {'Upper':>10} {'Std':>8}  Description\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    descriptions = {\n",
    "        'aw': 'Available water capacity (mm)',\n",
    "        'ks_alpha': 'Soil evap stress damping',\n",
    "        'kr_alpha': 'Root zone stress damping', \n",
    "        'ndvi_k': 'NDVI-Kcb slope',\n",
    "        'ndvi_0': 'NDVI-Kcb intercept',\n",
    "        'mad': 'Management allowable depletion',\n",
    "        'swe_alpha': 'Snow melt temp coefficient',\n",
    "        'swe_beta': 'Snow melt rate coefficient',\n",
    "    }\n",
    "    \n",
    "    for name, p in params.items():\n",
    "        init = p['initial_value']\n",
    "        if init is None:\n",
    "            init_str = 'auto'\n",
    "        elif isinstance(init, str):\n",
    "            init_str = init[:12]\n",
    "        else:\n",
    "            init_str = f\"{init:.2f}\"\n",
    "        print(f\"{name:<12} {init_str:>12} {p['lower_bound']:>10.2f} {p['upper_bound']:>10.2f} {p['std']:>8.2f}  {descriptions.get(name, '')}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "container_path = os.path.join(data, '3_Crane.swim')\n",
    "if os.path.exists(container_path):\n",
    "    show_parameter_table(config, container_path)\n",
    "else:\n",
    "    print(\"Container not found - run build_inputs.py first to see parameter table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-site-header",
   "metadata": {},
   "source": [
    "## 2. About the Study Site\n",
    "\n",
    "The S2 site is an irrigated alfalfa field in Crane, Oregon. According to IrrMapper data, this location has been irrigated since about 1996, making it a good test case for the irrigation scheduling component of SWIM-RS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-site-info",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:04.583316478Z",
     "start_time": "2026-01-28T06:35:04.521399640Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:46.681811Z",
     "iopub.status.busy": "2026-01-28T18:00:46.681328Z",
     "iopub.status.idle": "2026-01-28T18:00:46.688897Z",
     "shell.execute_reply": "2026-01-28T18:00:46.687541Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_feature = 'S2'\n",
    "\n",
    "print(f\"Site: {selected_feature}\")\n",
    "print(f\"Location: Crane, Oregon\")\n",
    "print(f\"Crop: Irrigated alfalfa\")\n",
    "print(f\"Date range: {config.start_dt} to {config.end_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0kt05thkp",
   "metadata": {},
   "source": [
    "### Optional: Query Data from SwimContainer\n",
    "\n",
    "If you've built the container using `build_inputs.py`, you can query ingested data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0o4oocpcpev",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:06.603701712Z",
     "start_time": "2026-01-28T06:35:04.585269995Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:46.693795Z",
     "iopub.status.busy": "2026-01-28T18:00:46.693273Z",
     "iopub.status.idle": "2026-01-28T18:00:49.052488Z",
     "shell.execute_reply": "2026-01-28T18:00:49.050813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query container data (optional - requires build_inputs.py to have been run)\n",
    "from swimrs.container import SwimContainer\n",
    "\n",
    "container_path = os.path.join(data, '3_Crane.swim')\n",
    "\n",
    "if os.path.exists(container_path):\n",
    "    container = SwimContainer.open(container_path, mode='r')\n",
    "    \n",
    "    # List available fields\n",
    "    print(f\"Fields in container: {container.field_uids}\")\n",
    "    \n",
    "    # Get all time series for a single field using field_timeseries\n",
    "    ts_df = container.query.field_timeseries('S2')\n",
    "    print(f\"\\nTime series shape: {ts_df.shape}\")\n",
    "    print(f\"Variables: {list(ts_df.columns)[:10]}...\")\n",
    "    \n",
    "    # Query specific data using dataframe with zarr paths\n",
    "    # Path structure: remote_sensing/{type}/{instrument}/{model}/{mask}\n",
    "    ndvi_df = container.query.dataframe(\"remote_sensing/ndvi/landsat/irr\", fields=['S2'])\n",
    "    print(f\"\\nNDVI observations: {ndvi_df.notna().sum().values[0]}\")\n",
    "    \n",
    "    etf_df = container.query.dataframe(\"remote_sensing/etf/landsat/ssebop/irr\", fields=['S2'])\n",
    "    print(f\"ETf observations: {etf_df.notna().sum().values[0]}\")\n",
    "    \n",
    "    # Show container status\n",
    "    print(\"\\n\" + container.query.status())\n",
    "    \n",
    "    container.close()\n",
    "else:\n",
    "    print(f\"Container not found at {container_path}\")\n",
    "    print(\"Run: cd data && python build_inputs.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-run-header",
   "metadata": {},
   "source": [
    "## 3. Run the Uncalibrated Model\n",
    "\n",
    "We define a helper function to run the SWIM model and capture its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:06.755682281Z",
     "start_time": "2026-01-28T06:35:06.688947844Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:49.057634Z",
     "iopub.status.busy": "2026-01-28T18:00:49.057126Z",
     "iopub.status.idle": "2026-01-28T18:00:49.083553Z",
     "shell.execute_reply": "2026-01-28T18:00:49.082818Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_fields(config, container, selected_feature, output_csv, start_date=None, end_date=None):\n",
    "    \"\"\"Run SWIM model using the process package and save output to CSV.\n",
    "    \n",
    "    Uses the modern process package workflow:\n",
    "    1. Build SwimInput from container\n",
    "    2. Run simulation with run_daily_loop_fast()\n",
    "    3. Convert DailyOutput to DataFrame with time series\n",
    "    4. Add ETf observations from container for comparison\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_date : str, optional\n",
    "        Override start date (YYYY-MM-DD). Use when met data doesn't cover full range.\n",
    "    end_date : str, optional  \n",
    "        Override end date (YYYY-MM-DD). Use when met data doesn't cover full range.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create temporary HDF5 for SwimInput\n",
    "    with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp:\n",
    "        temp_h5_path = tmp.name\n",
    "    \n",
    "    try:\n",
    "        # Build SwimInput from container\n",
    "        swim_input = build_swim_input(\n",
    "            container,\n",
    "            output_h5=temp_h5_path,\n",
    "            runoff_process=getattr(config, 'runoff_process', 'cn'),\n",
    "            etf_model=getattr(config, 'etf_target_model', 'ssebop'),\n",
    "            met_source=getattr(config, 'met_source', 'gridmet'),\n",
    "            fields=[selected_feature],\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "        )\n",
    "        \n",
    "        # Run simulation (uses fast JIT-compiled loop)\n",
    "        output, final_state = run_daily_loop_fast(swim_input)\n",
    "        \n",
    "        # Get time series data\n",
    "        n_days = swim_input.n_days\n",
    "        dates = pd.date_range(swim_input.start_date, periods=n_days, freq='D')\n",
    "        \n",
    "        # Get input time series for DataFrame\n",
    "        etr = swim_input.get_time_series('etr')\n",
    "        prcp = swim_input.get_time_series('prcp')\n",
    "        tmin = swim_input.get_time_series('tmin')\n",
    "        tmax = swim_input.get_time_series('tmax')\n",
    "        ndvi = swim_input.get_time_series('ndvi')\n",
    "        \n",
    "        # Build DataFrame (field index 0 since we're doing single field)\n",
    "        i = 0\n",
    "        df_data = {\n",
    "            # Model outputs\n",
    "            'et_act': output.eta[:, i],\n",
    "            'etref': etr[:, i],\n",
    "            'kc_act': output.etf[:, i],\n",
    "            'kc_bas': output.kcb[:, i],\n",
    "            'ks': output.ks[:, i],\n",
    "            'ke': output.ke[:, i],\n",
    "            'melt': output.melt[:, i],\n",
    "            'rain': output.rain[:, i],\n",
    "            'depl_root': output.depl_root[:, i],\n",
    "            'dperc': output.dperc[:, i],\n",
    "            'runoff': output.runoff[:, i],\n",
    "            'swe': output.swe[:, i],\n",
    "            'irrigation': output.irr_sim[:, i],\n",
    "            'gw_sim': output.gw_sim[:, i],\n",
    "            # Input time series\n",
    "            'ppt': prcp[:, i],\n",
    "            'tmin': tmin[:, i],\n",
    "            'tmax': tmax[:, i],\n",
    "            'tavg': (tmin[:, i] + tmax[:, i]) / 2.0,\n",
    "            'ndvi': ndvi[:, i],\n",
    "        }\n",
    "        \n",
    "        # Calculate derived columns\n",
    "        df_data['soil_water'] = swim_input.properties.awc[i] - output.depl_root[:, i]\n",
    "        \n",
    "        df = pd.DataFrame(df_data, index=dates)\n",
    "        \n",
    "        swim_input.close()\n",
    "        \n",
    "        # Load ETf observations from container for comparison\n",
    "        etf_model = getattr(config, 'etf_target_model', 'ssebop')\n",
    "        \n",
    "        for mask in ['inv_irr', 'irr']:\n",
    "            if etf_model == 'ensemble':\n",
    "                # Compute ensemble mean from all available models\n",
    "                known_models = ['ssebop', 'ptjpl', 'sims', 'geesebal', 'eemetric', 'disalexi']\n",
    "                mask_data = []\n",
    "                for model in known_models:\n",
    "                    etf_path = f\"remote_sensing/etf/landsat/{model}/{mask}\"\n",
    "                    try:\n",
    "                        etf_df = container.query.dataframe(etf_path, fields=[selected_feature])\n",
    "                        if selected_feature in etf_df.columns:\n",
    "                            mask_data.append(etf_df[selected_feature])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                \n",
    "                if mask_data:\n",
    "                    combined = pd.concat(mask_data, axis=1)\n",
    "                    ensemble_mean = combined.mean(axis=1)\n",
    "                    etf_series = ensemble_mean.reindex(dates)\n",
    "                    df[f'etf_{mask}'] = etf_series.values\n",
    "                    print(f\"Loaded ensemble ETf for {mask} from {len(mask_data)} models\")\n",
    "                else:\n",
    "                    print(f\"Warning: No ETf models found for {mask}\")\n",
    "                    df[f'etf_{mask}'] = np.nan\n",
    "            else:\n",
    "                etf_path = f\"remote_sensing/etf/landsat/{etf_model}/{mask}\"\n",
    "                try:\n",
    "                    etf_df = container.query.dataframe(etf_path, fields=[selected_feature])\n",
    "                    etf_series = etf_df[selected_feature].reindex(dates)\n",
    "                    df[f'etf_{mask}'] = etf_series.values\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not load ETf for {mask}: {e}\")\n",
    "                    df[f'etf_{mask}'] = np.nan\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        if os.path.exists(temp_h5_path):\n",
    "            os.remove(temp_h5_path)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f'\\nExecution time: {end_time - start_time:.2f} seconds\\n')\n",
    "\n",
    "    df.to_csv(output_csv)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-model",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:08.269360561Z",
     "start_time": "2026-01-28T06:35:06.757314240Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:49.086650Z",
     "iopub.status.busy": "2026-01-28T18:00:49.086431Z",
     "iopub.status.idle": "2026-01-28T18:00:51.098439Z",
     "shell.execute_reply": "2026-01-28T18:00:51.097710Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_feature = 'S2'\n",
    "out_csv = os.path.join(project_ws, f'combined_output_{selected_feature}_uncalibrated.csv')\n",
    "\n",
    "# Open container for model run\n",
    "container_path = os.path.join(data, '3_Crane.swim')\n",
    "container = SwimContainer.open(container_path, mode='r')\n",
    "\n",
    "try:\n",
    "    df = run_fields(config, container, selected_feature=selected_feature, output_csv=out_csv)\n",
    "finally:\n",
    "    container.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-inspect-output",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:08.391315988Z",
     "start_time": "2026-01-28T06:35:08.337919493Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:51.102318Z",
     "iopub.status.busy": "2026-01-28T18:00:51.102103Z",
     "iopub.status.idle": "2026-01-28T18:00:51.110154Z",
     "shell.execute_reply": "2026-01-28T18:00:51.109549Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Output shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "print(f\"\\nKey output columns:\")\n",
    "key_cols = ['et_act', 'etref', 'kc_act', 'kc_bas', 'ks', 'ke', 'melt', 'rain', \n",
    "            'depl_root', 'swe', 'ppt', 'irrigation', 'soil_water']\n",
    "for col in key_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  {col}: mean={df[col].mean():.3f}, max={df[col].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-viz-header",
   "metadata": {},
   "source": [
    "## 4. Visualize Model Output\n",
    "\n",
    "Let's examine a single year (2004) to see the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-viz-year",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:11.421326339Z",
     "start_time": "2026-01-28T06:35:08.393761449Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:51.113643Z",
     "iopub.status.busy": "2026-01-28T18:00:51.113441Z",
     "iopub.status.idle": "2026-01-28T18:00:54.169857Z",
     "shell.execute_reply": "2026-01-28T18:00:54.168525Z"
    }
   },
   "outputs": [],
   "source": [
    "ydf = df.loc['2004-01-01': '2004-12-31']\n",
    "print(f'Total irrigation: {ydf.irrigation.sum():.1f} mm')\n",
    "print(f'Total ET: {ydf.et_act.sum():.1f} mm')\n",
    "print(f'Total precipitation: {ydf.ppt.sum():.1f} mm')\n",
    "\n",
    "plot_swim_timeseries(ydf, ['et_act', 'etref', 'rain', 'melt', 'irrigation'], \n",
    "                     start='2004-01-01', end='2004-12-31', png_dir='et_uncalibrated.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-compare-header",
   "metadata": {},
   "source": [
    "## 5. Compare with Flux Tower Observations\n",
    "\n",
    "We compare three estimates of actual ET (mm/day):\n",
    "\n",
    "1. **SWIM ET**: Model-estimated actual evapotranspiration (daily)\n",
    "2. **OpenET Ensemble ET**: Remote sensing retrievals from OpenET (PT-JPL, SIMS, SSEBop, geeSEBAL) averaged together (ETf × ETo)\n",
    "3. **Flux ET**: Independent observations from the S2 eddy covariance tower (Volk et al.)\n",
    "\n",
    "We show two comparisons:\n",
    "- **Capture dates only**: Both methods compared only on Landsat overpass dates\n",
    "- **Full time series**: SWIM (daily) vs OpenET (interpolated between Landsat dates) on all flux tower days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compare-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:11.557902616Z",
     "start_time": "2026-01-28T06:35:11.482063896Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:54.174502Z",
     "iopub.status.busy": "2026-01-28T18:00:54.174061Z",
     "iopub.status.idle": "2026-01-28T18:00:54.196636Z",
     "shell.execute_reply": "2026-01-28T18:00:54.195770Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_et_estimates(combined_output_path, flux_data_path, irr=True):\n",
    "    \"\"\"Compare model ET and OpenET ensemble ET against flux tower observations.\n",
    "    \n",
    "    Returns two comparison DataFrames:\n",
    "    1. Capture dates only: Both methods on Landsat overpass dates only\n",
    "    2. Full time series: SWIM daily, OpenET interpolated, on all flux tower days\n",
    "    \n",
    "    Reports R², Pearson r, bias, and RMSE for each comparison.\n",
    "    \"\"\"\n",
    "    flux_data = pd.read_csv(flux_data_path, index_col='date', parse_dates=True)\n",
    "    flux_et = flux_data['ET_corr']  # Actual ET from flux tower (mm/day)\n",
    "\n",
    "    output = pd.read_csv(combined_output_path, index_col=0)\n",
    "    output.index = pd.to_datetime(output.index)\n",
    "\n",
    "    # Determine suffix based on irrigation mask\n",
    "    mask_suffix = 'irr' if irr else 'inv_irr'\n",
    "    \n",
    "    # OpenET ensemble models - compute mean ETf across available models\n",
    "    ensemble_models = ['ptjpl', 'sims', 'ssebop', 'geesebal']\n",
    "    etf_cols = []\n",
    "    for model in ensemble_models:\n",
    "        col_name = f'etf_{model}_{mask_suffix}'\n",
    "        if col_name in output.columns:\n",
    "            etf_cols.append(col_name)\n",
    "    \n",
    "    # Fallback to single SSEBop if ensemble columns not available\n",
    "    if not etf_cols:\n",
    "        etf_col = f'etf_{mask_suffix}'\n",
    "        if etf_col in output.columns:\n",
    "            etf_cols = [etf_col]\n",
    "            print(f\"Using single ETf column: {etf_col}\")\n",
    "        else:\n",
    "            print(f\"Warning: No ETf columns found for mask '{mask_suffix}'\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    print(f\"Using ETf columns: {etf_cols}\")\n",
    "    \n",
    "    # Compute ensemble mean ETf (ignoring NaN)\n",
    "    ensemble_etf = output[etf_cols].mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Calculate actual ET from OpenET ensemble: ETf × ETo (sparse, only on Landsat dates)\n",
    "    openet_et_sparse = ensemble_etf * output['etref']\n",
    "    \n",
    "    # Linear interpolation of OpenET to get daily values\n",
    "    openet_et_interp = openet_et_sparse.interpolate(method='linear')\n",
    "    \n",
    "    # Count original OpenET observations\n",
    "    n_openet_obs = openet_et_sparse.notna().sum()\n",
    "\n",
    "    # CAPTURE DATES ONLY comparison (OpenET sparse)\n",
    "    capture_df = pd.DataFrame({\n",
    "        'swim_et': output['et_act'],\n",
    "        'openet_et': openet_et_sparse,\n",
    "        'flux_et': flux_et\n",
    "    }).dropna()\n",
    "\n",
    "    # FULL TIME SERIES comparison (OpenET interpolated)\n",
    "    full_df = pd.DataFrame({\n",
    "        'swim_et': output['et_act'],\n",
    "        'openet_et': openet_et_interp,\n",
    "        'flux_et': flux_et\n",
    "    }).dropna()\n",
    "\n",
    "    def calc_metrics(df, col1, col2):\n",
    "        r, _ = stats.pearsonr(df[col1], df[col2])\n",
    "        r2 = r2_score(df[col1], df[col2])\n",
    "        rmse = np.sqrt(mean_squared_error(df[col1], df[col2]))\n",
    "        bias = (df[col2] - df[col1]).mean()\n",
    "        return r2, r, rmse, bias\n",
    "\n",
    "    # Capture dates metrics\n",
    "    r2_swim_cap, r_swim_cap, rmse_swim_cap, bias_swim_cap = calc_metrics(capture_df, 'flux_et', 'swim_et')\n",
    "    r2_openet_cap, r_openet_cap, rmse_openet_cap, bias_openet_cap = calc_metrics(capture_df, 'flux_et', 'openet_et')\n",
    "\n",
    "    # Full time series metrics\n",
    "    r2_swim_full, r_swim_full, rmse_swim_full, bias_swim_full = calc_metrics(full_df, 'flux_et', 'swim_et')\n",
    "    r2_openet_full, r_openet_full, rmse_openet_full, bias_openet_full = calc_metrics(full_df, 'flux_et', 'openet_et')\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(f\"CAPTURE DATES ONLY ({len(capture_df)} Landsat overpass dates)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Metric':<12} {'SWIM ET':>12} {'OpenET ET':>12}\")\n",
    "    print(\"-\" * 38)\n",
    "    print(f\"{'R²':<12} {r2_swim_cap:>12.3f} {r2_openet_cap:>12.3f}\")\n",
    "    print(f\"{'Pearson r':<12} {r_swim_cap:>12.3f} {r_openet_cap:>12.3f}\")\n",
    "    print(f\"{'Bias (mm)':<12} {bias_swim_cap:>12.3f} {bias_openet_cap:>12.3f}\")\n",
    "    print(f\"{'RMSE (mm)':<12} {rmse_swim_cap:>12.3f} {rmse_openet_cap:>12.3f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*70)\n",
    "    print(f\"FULL TIME SERIES ({len(full_df)} days, OpenET interpolated from {n_openet_obs} obs)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Metric':<12} {'SWIM ET':>12} {'OpenET ET':>12}\")\n",
    "    print(\"-\" * 38)\n",
    "    print(f\"{'R²':<12} {r2_swim_full:>12.3f} {r2_openet_full:>12.3f}\")\n",
    "    print(f\"{'Pearson r':<12} {r_swim_full:>12.3f} {r_openet_full:>12.3f}\")\n",
    "    print(f\"{'Bias (mm)':<12} {bias_swim_full:>12.3f} {bias_openet_full:>12.3f}\")\n",
    "    print(f\"{'RMSE (mm)':<12} {rmse_swim_full:>12.3f} {rmse_openet_full:>12.3f}\")\n",
    "\n",
    "    return full_df, capture_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compare-run",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:11.675226987Z",
     "start_time": "2026-01-28T06:35:11.559563434Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:54.199910Z",
     "iopub.status.busy": "2026-01-28T18:00:54.199675Z",
     "iopub.status.idle": "2026-01-28T18:00:54.319040Z",
     "shell.execute_reply": "2026-01-28T18:00:54.318193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use irrigated mask since this is an irrigated site\n",
    "flux_data = os.path.join(data, 'S2_daily_data.csv')\n",
    "full_df, capture_df = compare_et_estimates(out_csv, flux_data, irr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-scatter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:12.946034919Z",
     "start_time": "2026-01-28T06:35:11.676460814Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:54.322882Z",
     "iopub.status.busy": "2026-01-28T18:00:54.322650Z",
     "iopub.status.idle": "2026-01-28T18:00:55.286162Z",
     "shell.execute_reply": "2026-01-28T18:00:55.285513Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create 2x2 scatter plots for both comparisons\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Helper function to calculate metrics\n",
    "def calc_metrics(df, col1, col2):\n",
    "    r, _ = stats.pearsonr(df[col1], df[col2])\n",
    "    r2 = r2_score(df[col1], df[col2])\n",
    "    rmse = np.sqrt(mean_squared_error(df[col1], df[col2]))\n",
    "    return r2, r, rmse\n",
    "\n",
    "# Determine axis limits\n",
    "max_et = max(full_df['flux_et'].max(), full_df['swim_et'].max(), \n",
    "             full_df['openet_et'].max()) * 1.1\n",
    "\n",
    "# TOP ROW: Capture dates only\n",
    "r2_swim_cap, r_swim_cap, rmse_swim_cap = calc_metrics(capture_df, 'flux_et', 'swim_et')\n",
    "r2_openet_cap, r_openet_cap, rmse_openet_cap = calc_metrics(capture_df, 'flux_et', 'openet_et')\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(capture_df['flux_et'], capture_df['swim_et'], alpha=0.5, s=15)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('SWIM ET (mm/day)')\n",
    "ax.set_title(f'SWIM vs Flux - Capture Dates (n={len(capture_df)})\\n'\n",
    "             f'R² = {r2_swim_cap:.3f}, r = {r_swim_cap:.3f}, RMSE = {rmse_swim_cap:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(capture_df['flux_et'], capture_df['openet_et'], alpha=0.5, s=15)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('OpenET Ensemble ET (mm/day)')\n",
    "ax.set_title(f'OpenET vs Flux - Capture Dates (n={len(capture_df)})\\n'\n",
    "             f'R² = {r2_openet_cap:.3f}, r = {r_openet_cap:.3f}, RMSE = {rmse_openet_cap:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "# BOTTOM ROW: Full time series comparison\n",
    "r2_swim, r_swim, rmse_swim = calc_metrics(full_df, 'flux_et', 'swim_et')\n",
    "r2_openet, r_openet, rmse_openet = calc_metrics(full_df, 'flux_et', 'openet_et')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(full_df['flux_et'], full_df['swim_et'], alpha=0.3, s=10)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('SWIM ET (mm/day)')\n",
    "ax.set_title(f'SWIM vs Flux - Full Series (n={len(full_df)})\\n'\n",
    "             f'R² = {r2_swim:.3f}, r = {r_swim:.3f}, RMSE = {rmse_swim:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(full_df['flux_et'], full_df['openet_et'], alpha=0.3, s=10)\n",
    "ax.plot([0, max_et], [0, max_et], 'r--', label='1:1 line')\n",
    "ax.set_xlabel('Flux ET (mm/day)')\n",
    "ax.set_ylabel('OpenET Ensemble ET (mm/day)')\n",
    "ax.set_title(f'OpenET vs Flux - Full Series, interpolated (n={len(full_df)})\\n'\n",
    "             f'R² = {r2_openet:.3f}, r = {r_openet:.3f}, RMSE = {rmse_openet:.2f} mm')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, max_et)\n",
    "ax.set_ylim(0, max_et)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_scatter_uncalibrated.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9hx5wwxx9y",
   "metadata": {},
   "source": [
    "## 6. Mass Balance Check\n",
    "\n",
    "Now that we're integrating remote sensing data into a hydrological model, we must check mass conservation.\n",
    "\n",
    "Verify water conservation across the full simulation period. The water balance equation:\n",
    "\n",
    "**Starting Water + Inputs - Outputs = Ending Water**\n",
    "\n",
    "Where:\n",
    "- **Starting Water** = Initial Soil Water + Initial SWE\n",
    "- **Inputs** = Precipitation + Irrigation  \n",
    "- **Outputs** = ET + Deep Percolation + Runoff\n",
    "- **Ending Water** = Final Soil Water + Final SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z88px404u78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T06:35:13.092277105Z",
     "start_time": "2026-01-28T06:35:13.023561966Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-28T18:00:55.295934Z",
     "iopub.status.busy": "2026-01-28T18:00:55.295724Z",
     "iopub.status.idle": "2026-01-28T18:00:55.308136Z",
     "shell.execute_reply": "2026-01-28T18:00:55.307578Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mass_balance(df):\n",
    "    \"\"\"Compute full-run mass balance and display as a table.\n",
    "    \n",
    "    Water Balance: Starting Water + Inputs - Outputs = Ending Water\n",
    "    \n",
    "    Components:\n",
    "    - Starting Water: Initial soil water + Initial SWE\n",
    "    - Inputs: Total precipitation + Total irrigation\n",
    "    - Outputs: Total ET + Total deep percolation + Total runoff\n",
    "    - Ending Water: Final soil water + Final SWE\n",
    "    \"\"\"\n",
    "    # Starting conditions (first day values)\n",
    "    start_soil_water = df['soil_water'].iloc[0]\n",
    "    start_swe = df['swe'].iloc[0]\n",
    "    start_water = start_soil_water + start_swe\n",
    "    \n",
    "    # Ending conditions (last day values)\n",
    "    end_soil_water = df['soil_water'].iloc[-1]\n",
    "    end_swe = df['swe'].iloc[-1]\n",
    "    end_water = end_soil_water + end_swe\n",
    "    \n",
    "    # Inputs (sums over full period)\n",
    "    total_precip = df['ppt'].sum()\n",
    "    total_irrigation = df['irrigation'].sum()\n",
    "    total_inputs = total_precip + total_irrigation\n",
    "    \n",
    "    # Outputs (sums over full period)\n",
    "    total_et = df['et_act'].sum()\n",
    "    total_dperc = df['dperc'].sum()\n",
    "    total_runoff = df['runoff'].sum()\n",
    "    total_outputs = total_et + total_dperc + total_runoff\n",
    "    \n",
    "    # Mass balance check\n",
    "    # Expected: Start + Inputs - Outputs = End\n",
    "    # Residual: (Start + Inputs - Outputs) - End = 0 if balanced\n",
    "    expected_end = start_water + total_inputs - total_outputs\n",
    "    residual = expected_end - end_water\n",
    "    pct_error = (residual / total_inputs) * 100 if total_inputs > 0 else 0\n",
    "    \n",
    "    # Create summary table\n",
    "    print(\"=\" * 70)\n",
    "    print(\"MASS BALANCE SUMMARY\")\n",
    "    print(f\"Period: {df.index[0].strftime('%Y-%m-%d')} to {df.index[-1].strftime('%Y-%m-%d')} ({len(df)} days)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n--- STARTING WATER ---\")\n",
    "    print(f\"  Initial Soil Water:     {start_soil_water:>10.2f} mm\")\n",
    "    print(f\"  Initial SWE:            {start_swe:>10.2f} mm\")\n",
    "    print(f\"  TOTAL STARTING:         {start_water:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- INPUTS (+) ---\")\n",
    "    print(f\"  Precipitation:          {total_precip:>10.2f} mm\")\n",
    "    print(f\"  Irrigation:             {total_irrigation:>10.2f} mm\")\n",
    "    print(f\"  TOTAL INPUTS:           {total_inputs:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- OUTPUTS (-) ---\")\n",
    "    print(f\"  Evapotranspiration:     {total_et:>10.2f} mm\")\n",
    "    print(f\"  Deep Percolation:       {total_dperc:>10.2f} mm\")\n",
    "    print(f\"  Runoff:                 {total_runoff:>10.2f} mm\")\n",
    "    print(f\"  TOTAL OUTPUTS:          {total_outputs:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- ENDING WATER ---\")\n",
    "    print(f\"  Final Soil Water:       {end_soil_water:>10.2f} mm\")\n",
    "    print(f\"  Final SWE:              {end_swe:>10.2f} mm\")\n",
    "    print(f\"  TOTAL ENDING:           {end_water:>10.2f} mm\")\n",
    "    \n",
    "    print(\"\\n--- BALANCE CHECK ---\")\n",
    "    print(f\"  Expected End (Start + In - Out):  {expected_end:>10.2f} mm\")\n",
    "    print(f\"  Actual End:                       {end_water:>10.2f} mm\")\n",
    "    print(f\"  Residual (Error):                 {residual:>10.2f} mm\")\n",
    "    print(f\"  Error as % of Inputs:             {pct_error:>10.4f} %\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if abs(pct_error) < 0.01:\n",
    "        print(\"MASS BALANCE: CLOSED (error < 0.01%)\")\n",
    "    elif abs(pct_error) < 1.0:\n",
    "        print(\"MASS BALANCE: ACCEPTABLE (error < 1%)\")\n",
    "    else:\n",
    "        print(f\"MASS BALANCE: WARNING - {abs(pct_error):.2f}% error\")\n",
    "    \n",
    "    return {\n",
    "        'start_soil_water': start_soil_water,\n",
    "        'start_swe': start_swe,\n",
    "        'end_soil_water': end_soil_water,\n",
    "        'end_swe': end_swe,\n",
    "        'precip': total_precip,\n",
    "        'irrigation': total_irrigation,\n",
    "        'et': total_et,\n",
    "        'dperc': total_dperc,\n",
    "        'runoff': total_runoff,\n",
    "        'residual': residual,\n",
    "        'pct_error': pct_error\n",
    "    }\n",
    "\n",
    "# Run mass balance check\n",
    "balance = compute_mass_balance(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The uncalibrated model using default parameters shows the baseline performance before calibration. We compared both SWIM and the OpenET ensemble (PT-JPL, SIMS, SSEBop, geeSEBAL average) against independent flux tower observations.\n",
    "\n",
    "**Two comparison modes:**\n",
    "- **Capture dates**: Only Landsat overpass dates where we have satellite observations\n",
    "- **Full time series**: All flux tower days, with OpenET values interpolated between satellite dates\n",
    "\n",
    "**Key observations:**\n",
    "- The model isn't applying enough irrigation\n",
    "- The NDVI-to-Kcb relationship needs tuning for alfalfa\n",
    "- Soil parameters may not match the actual site conditions\n",
    "- OpenET ensemble provides robust remote sensing benchmark\n",
    "\n",
    "**Next step:** In notebook `02_calibration.ipynb`, we'll use PEST++ to calibrate the model parameters using SSEBop ETf and SNODAS SWE observations.\n",
    "\n",
    "**Key insight:** We're not using the flux data for calibration - it's only for validation. For calibration, we rely solely on widely-available remote sensing data (ETf and SNODAS SWE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
